---
title: "identify captures"
output: html_document
date: "2023-10-05"
---

```{r}
library(tidyverse)
library(shiny)
library(shinyjs)
library(leaflet)
library(sf)
```

# create a dataset of capture occurences of facilities and missiles
```{r}
facs <- read_csv("facilities.csv")[-1]
missiles <- read_csv("missiles.csv")[-1]
sat <- read_csv("sat.csv")[-1] # satellite photo polygons
```




```{r}
# create Simple Features DFs
facs_sf <- st_as_sf(facs, coords = c("lng", "lat"), remove = FALSE)
miss_sf <- st_as_sf(missiles, coords = c("lng", "lat"), remove = FALSE)
sat_sf <- st_as_sf(sat, wkt = "geometry")
sat_sf <- sat_sf %>% mutate(polygon_geometry = geometry) # duplicate polygons because otherwise they'll be removed
```

# Facilities Capture Occurences
```{r}
# Perform a spatial join to find points within polygons
fac_captures <- st_join(x = facs_sf, y = sat_sf, join = st_within)

# convert SF geometry columns to characters to avoid CSV file formatting issues
fac_captures$geometry <- st_as_text(fac_captures$geometry)
fac_captures$polygon_geometry <- st_as_text(fac_captures$polygon_geometry)

fac_captures <- fac_captures %>%
  mutate(pic_URL = ifelse(`Data Source` == "declass1",
                          paste("https://earthexplorer.usgs.gov/scene/metadata/full/5e839febdccb64b3/", 
                                `Display ID`, sep = ""),
                          ifelse(`Data Source` == "declass2",
                                 paste("https://earthexplorer.usgs.gov/scene/metadata/full/5e839ff7d71d4811/",
                                       `Display ID`, sep = ""),
                                 ifelse(`Data Source` == "declass3",
                                        paste("https://earthexplorer.usgs.gov/scene/metadata/full/5e7c41f3ffaaf662/",
                                              `Display ID`, sep = ""),
                                        "No URL available.")
                                 )
                          ))

# filter the dataset to remove cases where the photo was taken before construction started, INCLUDING unknown start dates
fac_caps_with_unknown <- fac_captures %>% 
  filter(ifelse(is.na(start_date), TRUE, start_date <= `Acquisition Date`))%>%
  as.data.frame() # convert from SF back to regular DF

write.csv(fac_caps_with_unknown, "fac_caps_with_unknown.csv")

# filter the dataset to remove cases where the photo was taken before construction started, EXCLUDING unknown start dates
fac_caps_no_unknown <- fac_captures %>% 
  filter(start_date <= `Acquisition Date`) %>%
  as.data.frame() # convert from SF back to regular DF

# fac_captures$`Display ID` <- as.character(fac_captures$`Display ID`) # this should be unec.

write.csv(fac_caps_no_unknown, "fac_caps_no_unknown.csv")
```



# Missiles Capture Occurences
```{r}
# Perform a spatial join to find points within polygons
miss_captures <- st_join(x = miss_sf, y = sat_sf, join = st_within)

# convert SF geometry columns to characters to avoid CSV file formatting issues
miss_captures$geometry <- st_as_text(miss_captures$geometry)
miss_captures$polygon_geometry <- st_as_text(miss_captures$polygon_geometry)

# filter the dataset to remove cases where the photo was taken before construction started
# note on dates: it's not clear how accurate/complete dates are. Are NA end dates b/c data wasn't available or b/c the site never stopped being used? Are start dates accurate?
miss_captures <- miss_captures %>% 
  filter(start_date <= `Acquisition Date`,
         ifelse(!is.na(end_date), end_date >= `Acquisition Date`, TRUE)) %>%
  as.data.frame() # convert from SF back to regular DF

# miss_captures$`Display ID` <- as.character(miss_captures$`Display ID`) # this should be unec.

write.csv(miss_captures, "miss_captures.csv")
```

